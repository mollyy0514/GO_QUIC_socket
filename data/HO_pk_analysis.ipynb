{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import swifter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import copy\n",
    "\n",
    "from collections import namedtuple\n",
    "from datetime import timedelta, datetime\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_with_suffix(directory, suffix):\n",
    "    matching_file = \"\"\n",
    "    # Iterate over files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        # Check if the file name ends with the specified suffix\n",
    "        if file_name.endswith(suffix):\n",
    "            # If it does, add it to the list of matching files\n",
    "            matching_file = os.path.join(directory, file_name)\n",
    "\n",
    "    return matching_file\n",
    "\n",
    "def get_ul_dl_files(directory, ul_port, dl_port):\n",
    "    ul_sent_file = None\n",
    "    dl_sent_file = None\n",
    "    ul_rcv_file = None\n",
    "    dl_rcv_file = None\n",
    "    ul_lost_file = None\n",
    "    dl_lost_file = None\n",
    "    \n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file starts with \"processed_sent\"\n",
    "        if filename.startswith(\"processed_sent\"):\n",
    "            # Split the file name by \"_\"\n",
    "            parts = filename.split(\"_\")\n",
    "            # Check if the last part of the file name is the UL port\n",
    "            if parts[-1].split(\".\")[0] == ul_port:\n",
    "                ul_sent_file = os.path.join(directory, filename)\n",
    "            # Check if the last part of the file name is the DL port\n",
    "            elif parts[-1].split(\".\")[0] == dl_port:\n",
    "                dl_sent_file = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if the file starts with \"processed_sent\"\n",
    "        if filename.startswith(\"processed_rcv\"):\n",
    "            # Split the file name by \"_\"\n",
    "            parts = filename.split(\"_\")\n",
    "            # Check if the last part of the file name is the UL port\n",
    "            if parts[-1].split(\".\")[0] == ul_port:\n",
    "                ul_rcv_file = os.path.join(directory, filename)\n",
    "            # Check if the last part of the file name is the DL port\n",
    "            elif parts[-1].split(\".\")[0] == dl_port:\n",
    "                dl_rcv_file = os.path.join(directory, filename)\n",
    "        \n",
    "        if filename.startswith(\"ul_real_lost_pk\"):\n",
    "            ul_lost_file = os.path.join(directory, filename)\n",
    "\n",
    "        if filename.startswith(\"dl_real_lost_pk\"):\n",
    "            dl_lost_file = os.path.join(directory, filename)\n",
    "\n",
    "    return {\"ul_sent_file\": ul_sent_file, \"dl_sent_file\": dl_sent_file, \"ul_rcv_file\": ul_rcv_file, \"dl_rcv_file\": dl_rcv_file, \"ul_lost_file\": ul_lost_file, \"dl_lost_file\": dl_lost_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2024-03-21\"\n",
    "exp_name = \"QUIC-inf\"\n",
    "device = \"sm01\"\n",
    "round = \"#06\"\n",
    "ul_time_diff = timedelta(seconds=0)\n",
    "dl_time_diff = timedelta(seconds=0)\n",
    "\n",
    "database = \"/Volumes/mollyT7/MOXA\"\n",
    "# database = \"/Users/molly/Desktop\"\n",
    "\n",
    "##### GET PORT #####\n",
    "device_to_ports = {\n",
    "    \"sm00\": {\"ul_port\": \"5200\", \"dl_port\": \"5201\"},\n",
    "    \"sm01\": {\"ul_port\": \"5202\", \"dl_port\": \"5203\"},\n",
    "    \"sm02\": {\"ul_port\": \"5204\", \"dl_port\": \"5205\"}\n",
    "}\n",
    "ul_port = device_to_ports[device][\"ul_port\"]\n",
    "dl_port = device_to_ports[device][\"dl_port\"]\n",
    "\n",
    "##### GET RRC FILE #####\n",
    "directory_path = f\"{database}/{date}/{exp_name}/{device}/{round}/data/\"\n",
    "rrc_suffix = \"_rrc.csv\"\n",
    "rrc_file = get_files_with_suffix(directory_path, rrc_suffix)\n",
    "parts = rrc_file.split(\"_\")\n",
    "if len(parts) >= 5:\n",
    "    start_time = \"_\".join(parts[3:5])\n",
    "    print(\"Start time:\", start_time)\n",
    "else:\n",
    "    print(\"File name does not contain enough parts.\")\n",
    "\n",
    "##### GET DATA FILES #####\n",
    "files_dict = get_ul_dl_files(directory_path, ul_port, dl_port)\n",
    "print(files_dict)\n",
    "ul_sent_file = files_dict[\"ul_sent_file\"]\n",
    "dl_sent_file = files_dict[\"dl_sent_file\"]\n",
    "ul_rcv_file = files_dict[\"ul_rcv_file\"]\n",
    "dl_rcv_file = files_dict[\"dl_rcv_file\"]\n",
    "ul_lost_file = files_dict[\"ul_lost_file\"]\n",
    "dl_lost_file = files_dict[\"dl_lost_file\"]\n",
    "\n",
    "###### EXTRACT TIME #####\n",
    "filename = os.path.basename(ul_sent_file)\n",
    "time = filename.split(\"_\")[2]\n",
    "print(\"Time:\", time)\n",
    "\n",
    "##### FIGURE PATH #####\n",
    "# figure_path = f\"/Users/molly/Desktop\"\n",
    "figure_path = f\"{database}/{date}/{exp_name}/{device}/{round}/statistics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {'Conn_Rel': 1, 'Conn_Req': 2, 'LTE_HO': 3, 'MN_HO': 4, 'MN_HO_to_eNB': 5, 'SN_setup': 6, 'SN_Rel': 7, 'SN_HO': 8, 'stable': 0, \n",
    "              'RLF_II': 9, 'RLF_III': 10, 'SCG_RLF': 11, 'Add_Scell': 12}\n",
    "colors_dict = {'Conn_Rel': '#ed5555', 'Conn_Req': '#78c4b1', 'LTE_HO': '#3ea357', 'MN_HO': '#e8803a', \n",
    "               'MN_HO_to_eNB': '#ad58c4', 'SN_setup': '#ddbfde', 'SN_Rel': '#a1543f', 'SN_HO': '#d4c68a', 'stable': '#878483',\n",
    "               'RLF_II': '#59a2c2', 'RLF_III': '#6494c4', 'SCG_RLF': '#646fc4'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HO Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_mi_ho(f):\n",
    "\n",
    "#     df = pd.read_csv(f)\n",
    "#     df[\"Timestamp\"] = df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x)) \n",
    "#     nr_pci = 'O'\n",
    "#     scells = []\n",
    "\n",
    "#     def NR_OTA(idx):\n",
    "\n",
    "#         if df[\"type_id\"].iloc[idx] == \"5G_NR_RRC_OTA_Packet\": return True\n",
    "#         else: return False\n",
    "    \n",
    "#     def LTE_SERV_INFO(idx):\n",
    "\n",
    "#         if df[\"type_id\"].iloc[idx] == \"LTE_RRC_Serv_Cell_Info\": return True\n",
    "#         else: return False\n",
    "    \n",
    "#     def find_1st_after(start_idx, target, look_after=1):\n",
    "#         for j in range(start_idx, len(df)):\n",
    "#             t_ = df[\"Timestamp\"].iloc[j]\n",
    "#             if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "#                 continue\n",
    "#             if (t_ - t).total_seconds() > look_after:\n",
    "#                 return None, None\n",
    "#             if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "#                 return t_, j\n",
    "#         return None, None\n",
    "    \n",
    "#     def find_1st_before(start_idx, target, look_before=1):\n",
    "#         for j in range(start_idx, -1, -1):\n",
    "#             t_ = df[\"Timestamp\"].iloc[j]\n",
    "#             if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "#                 continue\n",
    "#             if (t - t_).total_seconds() > look_before:\n",
    "#                 return None, None\n",
    "#             if df[target].iloc[j] not in [0,'0'] and not np.isnan(df[target].iloc[j]):\n",
    "#                 return t_, j\n",
    "#         return None, None\n",
    "    \n",
    "#     def find_1st_before_with_special_value(start_idx, target, target_value, look_before=1):\n",
    "#         for j in range(start_idx, -1, -1):\n",
    "#             t_ = df[\"Timestamp\"].iloc[j]\n",
    "#             if NR_OTA(j) or LTE_SERV_INFO(j):\n",
    "#                 continue\n",
    "#             if (t - t_).total_seconds() > look_before:\n",
    "#                 return None, None\n",
    "#             if df[target].iloc[j] in [target_value] and not np.isnan(df[target].iloc[j]):\n",
    "#                 return t_, j\n",
    "#         return None, None\n",
    "    \n",
    "#     def find_in_D_exact(targets):\n",
    "\n",
    "#         l = []\n",
    "#         # In l : (second, ho_type)\n",
    "#         for target in targets:\n",
    "#             for ho in D[target]:\n",
    "#                 l.append(((t - ho.start).total_seconds(), target))\n",
    "\n",
    "#         if len(l) != 0:\n",
    "#             for x in l:\n",
    "#                 if (x[0]== 0):\n",
    "#                     return x[1]\n",
    "        \n",
    "#         return None\n",
    "    \n",
    "#     def find_in_D_first_before(targets, look_before=1):\n",
    "\n",
    "#         l = []\n",
    "#         # In l : (second, ho_type)\n",
    "#         for target in targets:\n",
    "#             for ho in D[target]:\n",
    "#                 l.append(((t - ho.end).total_seconds(), target, ho))\n",
    "\n",
    "#         if len(l) != 0:\n",
    "#             closest = min(filter(lambda x: x[0] > 0, l), key=lambda x: x[0])\n",
    "#             if 0 <= closest[0] < look_before:\n",
    "#                 return closest[1], closest[2]\n",
    "        \n",
    "#         return None, None\n",
    "\n",
    "#     HO = namedtuple('HO',['start', 'end', 'others', 'trans'], defaults=[None,None,'',''])\n",
    "    \n",
    "#     D = {\n",
    "#         'Conn_Rel':[], \n",
    "#         'Conn_Req':[], # Setup\n",
    "#         'LTE_HO': [], # LTE -> newLTE\n",
    "#         'MN_HO': [], # LTE + NR -> newLTE + NR\n",
    "#         'MN_HO_to_eNB': [], # LTE + NR -> newLTE\n",
    "#         'SN_setup': [], # LTE -> LTE + NR => NR setup\n",
    "#         'SN_Rel': [], # LTE + NR -> LTE\n",
    "#         'SN_HO': [], # LTE + NR -> LTE + newNR  \n",
    "#         'RLF_II': [],\n",
    "#         'RLF_III': [],\n",
    "#         'SCG_RLF': [],\n",
    "#         'Add_SCell': [],\n",
    "#         }\n",
    "    \n",
    "#     for i in range(len(df)):\n",
    "\n",
    "#         # Pass NR RRC packet. In NSA mode, LTE RRC packet include NR packet message.\n",
    "#         if NR_OTA(i) or LTE_SERV_INFO(i):\n",
    "#             continue\n",
    "\n",
    "#         try: lte_pci, lte_earfcn\n",
    "#         except: \n",
    "#             lte_pci = df[\"PCI\"].iloc[i]\n",
    "#             lte_earfcn = int(df[\"Freq\"].iloc[i])\n",
    "\n",
    "#         others = ''\n",
    "#         t = df[\"Timestamp\"].iloc[i]\n",
    "\n",
    "#         if df[\"rrcConnectionRelease\"].iloc[i] == 1:\n",
    "#             D['Conn_Rel'].append(HO(start=t))\n",
    "#             nr_pci = 'O'\n",
    "\n",
    "#         if df[\"rrcConnectionRequest\"].iloc[i] == 1:\n",
    "            \n",
    "#             # Define end of rrcConnectionRequest to be rrcConnectionReconfigurationComplete or securityModeComplete.\n",
    "#             a = find_1st_after(i, 'rrcConnectionReconfigurationComplete',look_after=2)[0]\n",
    "#             b = find_1st_after(i, 'securityModeComplete',look_after=2)[0]\n",
    "        \n",
    "#             if a is None and b is None: end = None\n",
    "#             elif a is None and b is not None: end = b\n",
    "#             elif a is not None and b is None: end = a \n",
    "#             else: end = a if a > b else b\n",
    "            \n",
    "#             _, idx = find_1st_after(i, 'ueCapabilityInformation',look_after=1)\n",
    "#             if idx is not None:\n",
    "#                 sup_band = df['bandEUTRA'].iloc[idx]\n",
    "#                 others += f' supported band: {sup_band}.' \n",
    "\n",
    "#             serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "#             trans = f'({lte_pci}, {lte_earfcn}) -> ({serv_cell}, {serv_freq})'\n",
    "            \n",
    "#             # Check if caused by RLF III.\n",
    "#             a, idx = find_1st_before(i, 'rrcConnectionReestablishmentReject', look_before=1)\n",
    "#             if a is not None:\n",
    "#                 others += ' After RLF III.'\n",
    "\n",
    "#             D['Conn_Req'].append(HO(start=t,end=end,trans=trans, others=others))\n",
    "\n",
    "#             nr_pci = 'O'\n",
    "#             lte_pci = serv_cell\n",
    "#             lte_earfcn = serv_freq\n",
    "            \n",
    "#         if df[\"lte-rrc.t304\"].iloc[i] == 1:\n",
    "            \n",
    "#             end, _ = find_1st_after(i, 'rrcConnectionReconfigurationComplete')\n",
    "#             serv_cell, target_cell = df[\"PCI\"].iloc[i], int(df['lte_targetPhysCellId'].iloc[i])\n",
    "#             serv_freq, target_freq = int(df[\"Freq\"].iloc[i]), int(df['dl-CarrierFreq'].iloc[i])\n",
    "\n",
    "#             lte_pci = target_cell\n",
    "#             lte_earfcn = target_freq\n",
    "\n",
    "#             if df[\"SCellToAddMod-r10\"].iloc[i] == 1:\n",
    "#                 n =len(str(df[\"SCellIndex-r10.1\"].iloc[i]).split('@'))\n",
    "#                 others += f' Set up {n} SCell.'\n",
    "#             else:\n",
    "#                 scells = []\n",
    "            \n",
    "#             if serv_freq != target_freq:\n",
    "#                 a,b = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 1)\n",
    "#                 others += \" Inter frequency HO.\"\n",
    "#                 if a is not None:\n",
    "#                     others += \" Near after RLF.\"\n",
    "                \n",
    "#             if df[\"nr-rrc.t304\"].iloc[i] == 1 and df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "                \n",
    "#                 if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "#                     a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 2)\n",
    "                    \n",
    "#                     if a is not None:\n",
    "\n",
    "#                         ho_type, ho = find_in_D_first_before(['RLF_II', 'RLF_III'], 2)\n",
    "#                         others += f' Near after RLF of trans: {ho.trans}.'\n",
    "\n",
    "#                     else:\n",
    "                        \n",
    "#                         ho_type, _ = find_in_D_first_before(['MN_HO_to_eNB', 'SN_Rel'], 2)\n",
    "#                         if ho_type is not None:\n",
    "#                             others += f' Near after {ho_type}.'\n",
    "\n",
    "#                     ori_serv = nr_pci\n",
    "#                     nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "#                     trans = f'({serv_cell}, {serv_freq}) | {ori_serv} -> {nr_pci}'\n",
    "#                     D['SN_setup'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "#                 else:\n",
    "                    \n",
    "#                     nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "#                     trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "#                     D['MN_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "#             else:\n",
    "                \n",
    "#                 if serv_cell == target_cell and serv_freq == target_freq:\n",
    "\n",
    "#                     a, b = find_1st_before(i, \"scgFailureInformationNR-r15\")\n",
    "#                     if a is not None:\n",
    "#                         others += \" Caused by scg-failure.\"\n",
    "                    \n",
    "#                     orig_serv = nr_pci\n",
    "#                     nr_pci = 'O'\n",
    "#                     trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "#                     D['SN_Rel'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "                    \n",
    "#                 else:\n",
    "\n",
    "#                     a, _ = find_1st_before(i,\"rrcConnectionSetup\",3)\n",
    "#                     if a is not None:\n",
    "#                         others += ' Near After connection setup.'\n",
    "#                     if nr_pci == 'O':\n",
    "#                         trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {nr_pci}'\n",
    "#                         D['LTE_HO'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "#                     else:\n",
    "#                         orig_serv = nr_pci\n",
    "#                         nr_pci = 'O'\n",
    "#                         trans = f'({serv_cell}, {serv_freq}) -> ({target_cell}, {target_freq}) | {orig_serv} -> {nr_pci}'\n",
    "#                         D['MN_HO_to_eNB'].append(HO(start=t, end=end, others=others, trans=trans))\n",
    "\n",
    "\n",
    "#         if df[\"nr-rrc.t304\"].iloc[i] == 1 and not df[\"dualConnectivityPHR: setup (1)\"].iloc[i] == 1:\n",
    "\n",
    "#             end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "        \n",
    "#             serv_cell, serv_freq = df[\"PCI\"].iloc[i], int(df[\"Freq\"].iloc[i])\n",
    "#             orig_serv = nr_pci\n",
    "#             nr_pci = int(df['nr_physCellId'].iloc[i])\n",
    "#             trans = f'({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "#             D['SN_HO'].append(HO(start=t,end=end,trans=trans))\n",
    "\n",
    "\n",
    "#         if df[\"rrcConnectionReestablishmentRequest\"].iloc[i] == 1:\n",
    "\n",
    "#             end1, _ = find_1st_after(i, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "#             b, _ = find_1st_after(i, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "#             end2, _ = find_1st_after(i, 'securityModeComplete',look_after=3)\n",
    "\n",
    "#             others += ' ' + df[\"reestablishmentCause\"].iloc[i] + '.'\n",
    "#             scells = []\n",
    "\n",
    "#             c, _ = find_1st_before(i, 'scgFailureInformationNR-r15', 1)\n",
    "#             if c != None:\n",
    "#                 others  += ' caused by scgfailure.'\n",
    "                \n",
    "#             serv_cell, rlf_cell = df[\"PCI\"].iloc[i], int(df['physCellId.3'].iloc[i])\n",
    "#             serv_freq = int(df['Freq'].iloc[i])\n",
    "            \n",
    "#             # Type II & Type III\n",
    "#             if end1 is not None: \n",
    "\n",
    "#                 orig_serv = nr_pci\n",
    "#                 nr_pci = 'O'\n",
    "#                 _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "#                 rlf_freq = int(df['Freq'].iloc[idx])\n",
    "#                 trans = f'({rlf_cell}, {rlf_freq}) -> ({serv_cell}, {serv_freq}) | {orig_serv} -> {nr_pci}'\n",
    "#                 D['RLF_II'].append(HO(start=t,end=end1,others=others,trans=trans))\n",
    "\n",
    "#                 lte_pci = serv_cell\n",
    "#                 lte_earfcn = serv_freq\n",
    "\n",
    "#             elif b is not None and end2 is not None:\n",
    "                \n",
    "#                 orig_serv = nr_pci\n",
    "#                 nr_pci = 'O'\n",
    "#                 _, idx = find_1st_before_with_special_value(i, 'PCI', rlf_cell, look_before=10)\n",
    "#                 rlf_freq = int(df['Freq'].iloc[idx])\n",
    "\n",
    "#                 _, idx = find_1st_after(i, \"rrcConnectionRequest\", 2)\n",
    "#                 recon_cell, recon_freq = df['PCI'].iloc[idx], int(float(df['Freq'].iloc[idx]))\n",
    "                \n",
    "#                 trans = f'({rlf_cell}, {rlf_freq}) -> ({recon_cell}, {recon_freq}) | {orig_serv} -> {nr_pci}'\n",
    "#                 D['RLF_III'].append(HO(start=t,end=end2,others=others,trans=trans)) \n",
    "\n",
    "#                 # lte_pci, lte_earfcn will be updated in rrcConnectionRequest.     \n",
    "                \n",
    "#             else:\n",
    "\n",
    "#                 others+=' No end.'\n",
    "#                 D['RLF_II'].append(HO(start=t,others=others))\n",
    "#                 print('No end for RLF')\n",
    "\n",
    "#         if df[\"scgFailureInformationNR-r15\"].iloc[i] == 1:\n",
    "\n",
    "#             others += ' ' + df[\"failureType-r15\"].iloc[i] + '.'\n",
    "#             a, idx1 = find_1st_after(i, \"rrcConnectionReestablishmentRequest\", look_after=1)\n",
    "#             b, idx2 = find_1st_after(i, \"lte-rrc.t304\", look_after=10)\n",
    "\n",
    "#             if a is not None:\n",
    "\n",
    "#                 end1, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentComplete', look_after=1)\n",
    "#                 b, _ = find_1st_after(idx1, 'rrcConnectionReestablishmentReject', look_after=1)\n",
    "#                 end2 = find_1st_after(idx1, 'securityModeComplete',look_after=3)[0]\n",
    "\n",
    "#                 others += ' Result in rrcReestablishment.'\n",
    "                    \n",
    "#                 # Type II & Type III Result\n",
    "#                 if end1 is not None: \n",
    "#                     D['SCG_RLF'].append(HO(start=t,end=end1,others=others))\n",
    "#                 elif b is not None and end2 is not None: \n",
    "#                     D['SCG_RLF'].append(HO(start=t,end=end2,others=others))\n",
    "#                 else:\n",
    "#                     others += ' No end.'\n",
    "#                     D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "#                     print('No end for scg failure result in rrcReestablishment.')\n",
    "\n",
    "#             elif b is not None:\n",
    "\n",
    "#                 end, _ = find_1st_after(idx2, 'rrcConnectionReconfigurationComplete')\n",
    "#                 serv_cell, target_cell = df[\"PCI\"].iloc[idx2], df['lte_targetPhysCellId'].iloc[idx2]\n",
    "#                 serv_freq, target_freq = int(df[\"Freq\"].iloc[idx2]), df['dl-CarrierFreq'].iloc[idx2]\n",
    "#                 # We do not change nr_pci here. Instead, we will change it at gNB_Rel event.\n",
    "#                 trans = f'({serv_cell}, {serv_freq}) | {nr_pci} -> O'\n",
    "                \n",
    "#                 if serv_cell == target_cell and serv_freq == target_freq:\n",
    "#                     others += ' Result in gNB release.'\n",
    "#                     D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))\n",
    "#                 else:\n",
    "#                     others += ' Result in MN HO to eNB.'\n",
    "#                     D['SCG_RLF'].append(HO(start=t,end=end,others=others,trans=trans))                  \n",
    "\n",
    "#             else:\n",
    "\n",
    "#                 print('No end for scg failure.')\n",
    "#                 others += ' No end.'\n",
    "#                 D['SCG_RLF'].append(HO(start=t,others=others))\n",
    "        \n",
    "#         if df['SCellToAddMod-r10'].iloc[i] == 1 and df['physCellId-r10'].iloc[i] != 'nr or cqi report':\n",
    "\n",
    "#             others = ''\n",
    "#             pcis = str(df[\"physCellId-r10\"].iloc[i]).split('@')\n",
    "#             freqs = str(df[\"dl-CarrierFreq-r10\"].iloc[i]).split('@')\n",
    "#             orig_scells = scells\n",
    "#             scells = [(int(float(pci)), int(float(freq))) for pci, freq in zip(pcis, freqs)]\n",
    "\n",
    "#             others += f' Set up {len(scells)} SCell.'\n",
    "#             trans = f'{orig_scells} -> {scells}'\n",
    "\n",
    "#             end, _ = find_1st_after(i,'rrcConnectionReconfigurationComplete')\n",
    "            \n",
    "#             a, _ = find_1st_before(i, \"rrcConnectionReestablishmentRequest\", 3)\n",
    "#             if a is not None:\n",
    "#                 others += ' Near after RLF.'\n",
    "\n",
    "#             a = find_in_D_exact(['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel'])\n",
    "#             if a is not None:\n",
    "#                 others += f' With {a}.'\n",
    "\n",
    "#             D['Add_SCell'].append(HO(start=t,end=end,others=others, trans=trans))\n",
    "    \n",
    "#     return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class REPORTCONFIG:\n",
    "#     def __init__(self, name, parameter):\n",
    "#         self.name = name.split(' ')[0]  \n",
    "#         self.parameters = self.parse_parameter(parameter)\n",
    "    \n",
    "#     def parse_parameter(self, parameter):\n",
    "#         L = []\n",
    "#         start = False\n",
    "#         for i in range(len(parameter)):\n",
    "#             if parameter[i] == \"'\" and start == False:\n",
    "#                 s = ''\n",
    "#                 start = True\n",
    "#                 continue\n",
    "            \n",
    "#             if start:\n",
    "#                 if parameter[i] == \"'\":\n",
    "#                     L.append(s)\n",
    "#                     start = False\n",
    "#                 s += parameter[i]\n",
    "        \n",
    "#         P = dict()\n",
    "#         filter = '+-0123456789[]()&'\n",
    "#         for i in range(0,len(L),2):\n",
    "#             x = ''\n",
    "#             for c in L[i+1]:\n",
    "#                 if c in filter:\n",
    "#                     x += c\n",
    "#             try:\n",
    "#                 P[L[i]] = int(x)\n",
    "#             except:\n",
    "#                 P[L[i]] = x\n",
    "#         return P\n",
    "    \n",
    "#     def reset_name(self, name):\n",
    "#         self.name = name\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return self.name\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return self.name\n",
    "\n",
    "# class MEASOBJ:\n",
    "\n",
    "#     def __init__(self, obj, freq):\n",
    "#         self.name = obj\n",
    "#         self.freq = freq\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return f'({self.name}, {self.freq})'\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return f'({self.name}, {self.freq})'\n",
    "\n",
    "# def parse_measIdToAddMod(s):\n",
    "#     a = s.replace('(','')\n",
    "#     a = a.replace(')','')\n",
    "#     a = a.split('&')\n",
    "#     return (a[0], a[1], a[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MeasureReport(file):\n",
    "\n",
    "#     mi_rrc_df = pd.read_csv(file)\n",
    "#     mi_rrc_df[\"Timestamp\"] = mi_rrc_df[\"Timestamp\"].swifter.apply(lambda x: pd.to_datetime(x) + dt.timedelta(hours=8))\n",
    "#     unused = ['DL frequency','UL frequency', 'DL bandwidth', 'UL bandwidth', 'Cell Identity', 'TAC','Band ID', 'MCC', 'MNC']\n",
    "#     mi_rrc_df = mi_rrc_df.drop(columns=unused)\n",
    "#     mi_rrc_df = mi_rrc_df.dropna()    \n",
    "#     cols_to_covert = ['measObjectId', 'carrierFreq', 'carrierFreq-r15', 'lte-reportConfigId', 'lte-measIdToRemoveList', 'measId', 'ssbFrequency']\n",
    "#     mi_rrc_df[cols_to_covert] = mi_rrc_df[cols_to_covert].astype('str')\n",
    "\n",
    "#     measobj_dict, report_config_dict, measId_dict = {}, {}, {}\n",
    "#     nr_measobj_dict, nr_report_config_dict, nr_measId_dict = {}, {}, {}\n",
    "\n",
    "#     def reset():\n",
    "\n",
    "#         global measobj_dict, report_config_dict, measId_dict, nr_measobj_dict, nr_report_config_dict, nr_measId_dict  \n",
    "#         measobj_dict, report_config_dict, measId_dict = {}, {}, {}\n",
    "#         nr_measobj_dict, nr_report_config_dict, nr_measId_dict = {}, {}, {}\n",
    "\n",
    "#     MR = namedtuple('MR',['time', 'event', 'others'], defaults=[None,None,''])\n",
    "#     L = []\n",
    "\n",
    "#     RRC_connected = True\n",
    "#     Unknown = REPORTCONFIG('Unknown', {})\n",
    "\n",
    "#     for i in range(len(mi_rrc_df)):\n",
    "\n",
    "#         if mi_rrc_df['type_id'].iloc[i] == \"5G_NR_RRC_OTA_Packet\" or mi_rrc_df['type_id'].iloc[i] == \"LTE_RRC_Serv_Cell_Info\":\n",
    "#             continue\n",
    "\n",
    "#         time = mi_rrc_df['Timestamp'].iloc[i]\n",
    "#         others = ''\n",
    "        \n",
    "#         # if mi_rrc_df[\"rrcConnectionRelease\"].iloc[i] == 1:      \n",
    "#         #     reset()\n",
    "\n",
    "#         if mi_rrc_df[\"lte-measIdToRemoveList\"].iloc[i] != '0':\n",
    "\n",
    "#             measIdToRemove_list = mi_rrc_df[\"lte-measIdToRemoveList\"].iloc[i].split('@')\n",
    "#             if len(measIdToRemove_list) == 32:\n",
    "#                 measId_dict = {}\n",
    "#             elif len(measId_dict) != 0:\n",
    "#                 for a in range(len(measIdToRemove_list)):\n",
    "#                     try: measId_dict.pop(measIdToRemove_list[a])\n",
    "#                     except: pass\n",
    "\n",
    "#         if mi_rrc_df[\"lte-measurementReport\"].iloc[i] == 1:\n",
    "            \n",
    "#             others += 'E-UTRAN'\n",
    "#             id = str(int(float(mi_rrc_df['measId'].iloc[i])))\n",
    "\n",
    "#             try:\n",
    "#                 x = measId_dict[id]\n",
    "#                 event = report_config_dict[x[1]]\n",
    "#                 mr = MR(time = time, event = event, others = others)\n",
    "#             except:\n",
    "#                 mr = MR(time = time, event = copy.deepcopy(Unknown), others = others)\n",
    "\n",
    "#             L.append(mr)\n",
    "\n",
    "#         if mi_rrc_df[\"nr-measurementReport\"].iloc[i] == 1:\n",
    "            \n",
    "#             others += 'NR'\n",
    "#             id = str(int(float(mi_rrc_df['measId'].iloc[i])))\n",
    "\n",
    "#             try:\n",
    "#                 x = nr_measId_dict[id]\n",
    "#                 event = nr_report_config_dict[x[1]]\n",
    "#                 mr = MR(time = time, event = event, others = others)\n",
    "#             except:\n",
    "#                 mr = MR(time = time, event = copy.deepcopy(Unknown), others = others)\n",
    "            \n",
    "#             L.append(mr)\n",
    "\n",
    "#         if mi_rrc_df[\"lte-MeasObjectToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "#             Id_list = mi_rrc_df[\"measObjectId\"].iloc[i].split('@')\n",
    "#             measobj_list = mi_rrc_df[\"measObject\"].iloc[i].split('@')\n",
    "#             carrierFreq_list = mi_rrc_df[\"carrierFreq\"].iloc[i].split('@')\n",
    "#             carrierFreq_r15_list = mi_rrc_df[\"carrierFreq-r15\"].iloc[i].split('@')\n",
    "            \n",
    "#             for a in range(len(Id_list)):\n",
    "#                 if measobj_list[a] == \"measObjectEUTRA (0)\":\n",
    "#                     measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], carrierFreq_list[0])\n",
    "#                     carrierFreq_list.pop(0)\n",
    "#                 elif measobj_list[a] == \"measObjectNR-r15 (5)\":\n",
    "#                     measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], carrierFreq_r15_list[0])\n",
    "#                     carrierFreq_r15_list.pop(0)\n",
    "    \n",
    "\n",
    "#         if mi_rrc_df[\"nr-MeasObjectToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "#             Id_list = mi_rrc_df[\"measObjectId\"].iloc[i].split('@')\n",
    "#             measobj_list = mi_rrc_df[\"measObject\"].iloc[i].split('@')\n",
    "#             ssbFrequency_list = mi_rrc_df[\"ssbFrequency\"].iloc[i].split('@')\n",
    "\n",
    "#             for a in range(len(Id_list)):\n",
    "#                 if measobj_list[a] == \"measObjectNR (0)\":\n",
    "#                     nr_measobj_dict[Id_list[a]] = MEASOBJ(measobj_list[a], ssbFrequency_list[0])\n",
    "#                     ssbFrequency_list.pop(0)     \n",
    "\n",
    "            \n",
    "#         if mi_rrc_df[\"lte-ReportConfigToAddMod\"].iloc[i] == 1:\n",
    "\n",
    "#             reportConfigId_list = mi_rrc_df[\"lte-reportConfigId\"].iloc[i].split('@')\n",
    "#             eventId_list = mi_rrc_df[\"lte-eventId\"].iloc[i].split('@')\n",
    "#             parameter_list = mi_rrc_df[\"lte-parameter\"].iloc[i].split('@')\n",
    "#             for a in range(len(reportConfigId_list)):\n",
    "#                 report_config_dict[reportConfigId_list[a]] = REPORTCONFIG(eventId_list[a], parameter_list[a])\n",
    "\n",
    "\n",
    "#         if mi_rrc_df[\"nr-ReportConfigToAddMod\"].iloc[i] == 1: #############\n",
    "\n",
    "#             reportConfigId_list = mi_rrc_df[\"nr-reportConfigId\"].iloc[i].split('@')\n",
    "#             eventId_list = mi_rrc_df[\"nr-eventId\"].iloc[i].split('@')\n",
    "#             parameter_list = mi_rrc_df[\"nr-parameter\"].iloc[i].split('@')\n",
    "#             for a in range(len(reportConfigId_list)):\n",
    "#                 nr_report_config_dict[reportConfigId_list[a]] = REPORTCONFIG(eventId_list[a], parameter_list[a])\n",
    "\n",
    "#         if mi_rrc_df[\"lte-MeasIdToAddMod\"].iloc[i] != '0':\n",
    "\n",
    "#             MeasIdToAdd_list = mi_rrc_df[\"lte-MeasIdToAddMod\"].iloc[i].split('@')\n",
    "#             for a in range(len(MeasIdToAdd_list)):\n",
    "#                 x = parse_measIdToAddMod(MeasIdToAdd_list[a])\n",
    "#                 measId_dict[x[0]] = (x[1],x[2])\n",
    "\n",
    "\n",
    "#         if mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i] != '0' and mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i] != 0:\n",
    "\n",
    "#             MeasIdToAdd_list = mi_rrc_df[\"nr-MeasIdToAddMod\"].iloc[i].split('@')\n",
    "#             for a in range(len(MeasIdToAdd_list)):\n",
    "#                 x = parse_measIdToAddMod(MeasIdToAdd_list[a])\n",
    "#                 nr_measId_dict[x[0]] = (x[1],x[2])\n",
    "\n",
    "#     # Sort to Dict\n",
    "#     types = ['eventA1','eventA2','E-UTRAN-eventA3', 'eventA5', 'eventA6','NR-eventA3', 'eventB1-NR-r15','reportCGI', 'reportStrongestCells', 'others']\n",
    "#     D = {k: [] for k in types}\n",
    "\n",
    "#     for mr in L:\n",
    "\n",
    "#         if 'E-UTRAN' in mr.others and 'eventA1' in mr.event.name:\n",
    "#             D['eventA1'].append(mr)\n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'eventA2' in mr.event.name:\n",
    "#             D['eventA2'].append(mr)  \n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'eventA3' in mr.event.name:\n",
    "#             D['E-UTRAN-eventA3'].append(mr)\n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'eventA5' in mr.event.name:\n",
    "#             D['eventA5'].append(mr)\n",
    "\n",
    "#         elif 'E-UTRAN' in mr.others and 'eventA6' in mr.event.name:\n",
    "#             D['eventA6'].append(mr)  \n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'eventB1-NR-r15' in mr.event.name:\n",
    "#             D['eventB1-NR-r15'].append(mr)\n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'reportCGI' in mr.event.name:\n",
    "#             D['reportCGI'].append(mr)\n",
    "        \n",
    "#         elif 'E-UTRAN' in mr.others and 'reportStrongestCells' in mr.event.name:\n",
    "#             D['reportStrongestCells'].append(mr)\n",
    "        \n",
    "#         elif 'NR' in mr.others and 'eventA3' in mr.event.name:\n",
    "#             D['NR-eventA3'].append(mr)       \n",
    "        \n",
    "#         else:\n",
    "#             D['others'].append(mr)\n",
    "\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map MeasureReport to HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_MR_HO(MRs, HOs):\n",
    "\n",
    "#     map_ho_types = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel', 'SN_HO', ]\n",
    "#     map_mr_types = ['E-UTRAN-eventA3', 'eventA5', 'eventB1-NR-r15', 'NR-eventA3']\n",
    "\n",
    "#     D = {'LTE_HO': [], 'NR_HO': [], 'SN_setup': []}\n",
    "\n",
    "#     for lte_ho_type in ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB']:\n",
    "#         for ho in HOs[lte_ho_type]:\n",
    "#             for mr_type in ['E-UTRAN-eventA3', 'eventA5']:\n",
    "                \n",
    "#                 for mr in MRs[mr_type]:\n",
    "#                     # The current mapping way may map a HO with repeated measurement report.\n",
    "#                     dif = (ho.start - mr.time).total_seconds()\n",
    "#                     if 0 < dif < 0.5:\n",
    "#                         D['LTE_HO'].append((mr, ho, lte_ho_type))\n",
    "\n",
    "#     for nr_ho_type in ['SN_Rel', 'SN_HO']:\n",
    "#         for ho in HOs[nr_ho_type]:\n",
    "#             for mr in MRs['NR-eventA3']:\n",
    "\n",
    "#                 dif = (ho.start - mr.time).total_seconds()\n",
    "#                 if 0 < dif < 0.5:\n",
    "#                     D['NR_HO'].append((mr, ho, nr_ho_type))\n",
    "\n",
    "#     for ho in HOs['SN_setup']:\n",
    "#         for mr in MRs['eventB1-NR-r15']:\n",
    "\n",
    "#             dif = (ho.start - mr.time).total_seconds()\n",
    "#             if 0 < dif < 0.5:\n",
    "#                 D['SN_setup'].append((mr, ho, 'SN_setup'))\n",
    "\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correct MR with HO\n",
    "# def correct_MR_with_HO(MRs, HOs):\n",
    "#     MR = namedtuple('MR',['time', 'event', 'others'], defaults=[None,None,''])\n",
    "#     new_MRs = copy.deepcopy(MRs)\n",
    "#     del new_MRs['others']\n",
    "\n",
    "#     for mr in MRs['others']:\n",
    "#         if 'E-UTRAN' in mr.others:\n",
    "#             for ho in HOs['LTE_HO'] + HOs['MN_HO']:\n",
    "#                 if 0.3 > (ho.start - mr.time).total_seconds() > 0:\n",
    "#                     mr.event.reset_name('eventA3')\n",
    "#                     new_MRs['E-UTRAN-eventA3'].append(MR(time = mr.time, event = mr.event, others = mr.others))\n",
    "    \n",
    "#         elif 'NR' in mr.others:\n",
    "#             for ho in HOs['SN_HO']:\n",
    "#                 if 0.3 > (ho.start - mr.time).total_seconds() > 0:\n",
    "#                     mr.event.reset_name('eventA3')\n",
    "#                     new_MRs['NR-eventA3'].append(MR(time = mr.time, event = mr.event, others = mr.others))\n",
    "    \n",
    "#     return new_MRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HO Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For colored output text\n",
    "# class bcolors:\n",
    "#     HEADER = '\\033[95m'\n",
    "#     OKBLUE = '\\033[94m'\n",
    "#     OKCYAN = '\\033[96m'\n",
    "#     OKGREEN = '\\033[92m'\n",
    "#     WARNING = '\\033[93m'\n",
    "#     FAIL = '\\033[91m'\n",
    "#     ENDC = '\\033[0m'\n",
    "#     BOLD = '\\033[1m'\n",
    "#     UNDERLINE = '\\033[4m'\n",
    "    \n",
    "# def print_trans(HOs, p=True, mappings=None):\n",
    "\n",
    "#     All_HOs = []\n",
    "#     selected = ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB', 'SN_setup', 'SN_Rel', 'SN_HO', \n",
    "#     'Conn_Req' ,'RLF_II', 'RLF_III', 'SCG_RLF']\n",
    "\n",
    "#     def find_mr(target, ho):\n",
    "#         for mapping in target:\n",
    "#             map_ho = mapping[1]\n",
    "#             if ho == map_ho:\n",
    "#                 mr = mapping[0]\n",
    "#                 return mr\n",
    "#         return None\n",
    "\n",
    "#     for type in selected:\n",
    "\n",
    "#         for ho in HOs[type]:\n",
    "\n",
    "#             if type in ['LTE_HO', 'MN_HO', 'MN_HO_to_eNB'] and mappings is not None:\n",
    "            \n",
    "#                 target = mappings['LTE_HO']\n",
    "#                 mr = find_mr(target, ho)\n",
    "                \n",
    "#                 if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "#                     All_HOs.append([type, ho, mr])\n",
    "#                 else:\n",
    "#                     All_HOs.append([type, ho])\n",
    "\n",
    "#             elif type in ['SN_Rel', 'SN_HO'] and mappings is not None:\n",
    "            \n",
    "#                 target = mappings['NR_HO']\n",
    "#                 mr = find_mr(target, ho)\n",
    "\n",
    "#                 if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "#                     All_HOs.append([type, ho, mr])\n",
    "#                 else:\n",
    "#                     All_HOs.append([type, ho])\n",
    "\n",
    "#             elif type in ['SN_setup'] and mappings is not None:\n",
    "            \n",
    "#                 target = mappings['SN_setup']\n",
    "#                 mr = find_mr(target, ho)\n",
    "\n",
    "#                 if mr is not None and 0 < (ho.start - mr.time).total_seconds() < 0.5: \n",
    "#                     All_HOs.append([type, ho, mr])\n",
    "#                 else:\n",
    "#                     All_HOs.append([type, ho])\n",
    "                \n",
    "#             else:\n",
    "#                 All_HOs.append([type, ho])\n",
    "\n",
    "#     All_HOs = sorted(All_HOs, key = lambda x: x[1].start)\n",
    "\n",
    "#     if p:\n",
    "#         for ho in All_HOs:\n",
    "#             if len(ho) == 3:\n",
    "#                 print(f'{ho[1].start} | {bcolors.OKBLUE}{ho[0]}{bcolors.ENDC} | {bcolors.OKCYAN}{ho[1].trans}{bcolors.ENDC} | {bcolors.OKGREEN}{ho[2].event.name}{bcolors.ENDC} | {ho[2].event.parameters}')\n",
    "#             elif len(ho) == 2:\n",
    "#                 print(f'{ho[1].start} | {bcolors.OKBLUE}{ho[0]}{bcolors.ENDC} | {bcolors.OKCYAN}{ho[1].trans}{bcolors.ENDC}')\n",
    "\n",
    "#     return All_HOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOs = parse_mi_ho(rrc_file)\n",
    "# HOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-18 16:07:00.145172 | \u001b[94mSN_Rel\u001b[0m | \u001b[96m(472, 3050) | O -> O\u001b[0m\n",
      "2024-04-18 16:07:14.737798 | \u001b[94mLTE_HO\u001b[0m | \u001b[96m(472, 3050) -> (307, 3050) | O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:07:15.292878 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(307, 3050) | O -> 307\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:07:19.021941 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(307, 3050) -> (285, 3050) | 307\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:07:19.802324 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(285, 3050) | 307 -> 285\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:07:45.990906 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(285, 3050) -> (277, 3050) | 285\u001b[0m\n",
      "2024-04-18 16:07:47.339294 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(277, 3050) | 285 -> 277\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:08:00.321846 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(277, 3050) | 277 -> 269\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:08:00.981136 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(277, 3050) -> (269, 3050) | 269\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:08:15.130894 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(269, 3050) | 269 -> 128\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:08:15.801649 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(269, 3050) -> (128, 3050) | 128\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:08:23.009539 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(128, 3050) | 128 -> 136\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:08:23.466151 | \u001b[94mMN_HO_to_eNB\u001b[0m | \u001b[96m(128, 3050) -> (136, 3050) | 136 -> O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:08:23.843763 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(136, 3050) | O -> 136\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:08:28.789516 | \u001b[94mMN_HO_to_eNB\u001b[0m | \u001b[96m(136, 3050) -> (201, 3050) | 136 -> O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:08:29.325332 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(201, 3050) | O -> 701\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:08:36.325355 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(201, 3050) -> (110, 3050) | 701\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:08:40.972748 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(110, 3050) | 701 -> 430\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:08:54.542772 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(110, 3050) | 430 -> 731\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:09:38.432406 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(110, 3050) | 731 -> 414\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:09:39.089860 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(110, 3050) | 414 -> 430\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:09:47.964458 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(110, 3050) -> (414, 3050) | 430\u001b[0m\n",
      "2024-04-18 16:09:50.566535 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(414, 3050) -> (422, 3050) | 430\u001b[0m\n",
      "2024-04-18 16:09:55.150200 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(422, 3050) | 430 -> 422\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:09:57.460339 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(422, 3050) -> (414, 3050) | 422\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:09:58.044129 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(414, 3050) | 422 -> 414\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:10:03.983190 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(414, 3050) -> (122, 3050) | 414\u001b[0m\n",
      "2024-04-18 16:10:04.590830 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(122, 3050) | 414 -> 622\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:10:07.902235 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(122, 3050) | 622 -> 358\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:10:09.770193 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(122, 3050) -> (358, 3050) | 358\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:10:17.520716 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(358, 3050) -> (350, 3050) | 358\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:10:18.422056 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(350, 3050) | 358 -> 350\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:10:26.100967 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(350, 3050) -> (468, 3050) | 350\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:10:26.887540 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(468, 3050) | 350 -> 468\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:11:24.762083 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(468, 3050) -> (394, 3050) | 468\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:11:25.382127 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(394, 3050) | 468 -> 394\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:11:41.823689 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(394, 3050) -> (17, 3050) | 394\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:11:42.227562 | \u001b[94mRLF_II\u001b[0m | \u001b[96m(17, 3050) -> (6, 1750) | 394 -> O\u001b[0m\n",
      "2024-04-18 16:11:43.325580 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(6, 1750) | O -> 171\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:11:46.112690 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(6, 1750) | 171 -> 138\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:11:49.765427 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(6, 1750) | 138 -> 183\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:11:56.542330 | \u001b[94mRLF_II\u001b[0m | \u001b[96m(6, 1750) -> (143, 1750) | 183 -> O\u001b[0m\n",
      "2024-04-18 16:11:57.053319 | \u001b[94mLTE_HO\u001b[0m | \u001b[96m(143, 1750) -> (183, 1750) | O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:11:57.434111 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(183, 1750) | O -> 175\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:11:57.803534 | \u001b[94mMN_HO_to_eNB\u001b[0m | \u001b[96m(183, 1750) -> (444, 1750) | 175 -> O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:11:58.087612 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(444, 1750) | O -> 183\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:12:00.279650 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(444, 1750) | 183 -> 143\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:01.641178 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(444, 1750) -> (369, 1750) | 143\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:02.180740 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(369, 1750) -> (377, 1750) | 143\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:03.025405 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(377, 1750) -> (143, 1750) | 143\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:04.055845 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(143, 1750) | 143 -> 635\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:04.463842 | \u001b[94mMN_HO_to_eNB\u001b[0m | \u001b[96m(143, 1750) -> (135, 1750) | 635 -> O\u001b[0m\n",
      "2024-04-18 16:12:04.799550 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(135, 1750) | O -> 635\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:12:11.088964 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(135, 1750) -> (111, 1750) | 635\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:12.196429 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(111, 1750) | 635 -> 119\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:13.494282 | \u001b[94mMN_HO_to_eNB\u001b[0m | \u001b[96m(111, 1750) -> (135, 1750) | 119 -> O\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:14.119675 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(135, 1750) | O -> 106\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:12:15.816502 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(135, 1750) | 106 -> 635\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:16.705826 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(135, 1750) | 635 -> 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:17.365546 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(135, 1750) -> (383, 1750) | 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:18.850389 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(383, 1750) | 243 -> 883\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:25.159755 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(383, 1750) | 883 -> 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:27.533500 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(383, 1750) -> (243, 1750) | 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:12:32.186926 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(243, 1750) | 243 -> 875\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:12:39.339360 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(243, 1750) | 875 -> 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:13:44.702198 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(243, 1750) -> (378, 1750) | 243\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:13:45.298315 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(378, 1750) | 243 -> 378\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:14:02.091630 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(378, 1750) -> (84, 1750) | 378\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:14:02.701272 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(84, 1750) | 378 -> 84\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:14:05.428268 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(84, 1750) -> (92, 1750) | 84\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:14:05.738038 | \u001b[94mRLF_II\u001b[0m | \u001b[96m(84, 1750) -> (325, 1750) | 84 -> O\u001b[0m\n",
      "2024-04-18 16:14:06.283885 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(325, 1750) | O -> 825\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:14:07.109629 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(325, 1750) -> (84, 1750) | 825\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:14:07.477353 | \u001b[94mSCG_RLF\u001b[0m | \u001b[96m(84, 1750) | 825 -> O\u001b[0m\n",
      "2024-04-18 16:14:07.552358 | \u001b[94mSN_Rel\u001b[0m | \u001b[96m(84, 1750) | 825 -> O\u001b[0m\n",
      "2024-04-18 16:14:08.108659 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(84, 1750) | O -> 84\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:14:11.106278 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(84, 1750) | 84 -> 271\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:14:18.119943 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(84, 1750) -> (271, 1750) | 271\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:14:31.844720 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(271, 1750) | 271 -> 287\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:14:36.319473 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(271, 1750) -> (287, 1750) | 287\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:15:20.283763 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(287, 1750) -> (271, 1750) | 287\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:15:26.805431 | \u001b[94mRLF_II\u001b[0m | \u001b[96m(271, 1750) -> (287, 1750) | 287 -> O\u001b[0m\n",
      "2024-04-18 16:15:27.327855 | \u001b[94mSN_setup\u001b[0m | \u001b[96m(287, 1750) | O -> 87\u001b[0m | \u001b[92meventB1-NR-r15\u001b[0m | {'thr': '[-111&-110)', 'hys': 0, 'ttt': 100}\n",
      "2024-04-18 16:15:30.844958 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(287, 1750) -> (87, 1750) | 87\u001b[0m\n",
      "2024-04-18 16:15:42.245889 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(87, 1750) | 87 -> 329\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n",
      "2024-04-18 16:15:44.632599 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(87, 1750) -> (329, 1750) | 329\u001b[0m\n",
      "2024-04-18 16:15:57.320032 | \u001b[94mMN_HO\u001b[0m | \u001b[96m(329, 1750) -> (44, 1750) | 329\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 2, 'hys': 1, 'ttt': 160}\n",
      "2024-04-18 16:15:58.950002 | \u001b[94mSN_HO\u001b[0m | \u001b[96m(44, 1750) | 329 -> 44\u001b[0m | \u001b[92meventA3\u001b[0m | {'off': 6, 'hys': 1, 'ttt': 640}\n"
     ]
    }
   ],
   "source": [
    "MRs = MeasureReport(rrc_file)\n",
    "MRs = correct_MR_with_HO(MRs, HOs)\n",
    "mappings = map_MR_HO(MRs, HOs)\n",
    "ordered_HOs1 = print_trans(HOs, mappings=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since MobileInsight rrc file may start before the experient start time,\n",
    "## so we need to filter out the data\n",
    "# Define the threshold timestamp\n",
    "threshold_timestamp = datetime.strptime(start_time, '%Y-%m-%d_%H-%M-%S')\n",
    "# Filter the data based on the threshold timestamp\n",
    "filtered_time_ordered_HO = [entry for entry in ordered_HOs1 if entry[1].start > threshold_timestamp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_sent_df = pd.read_csv(ul_sent_file, sep='@')\n",
    "dl_sent_df = pd.read_csv(dl_sent_file, sep='@')\n",
    "\n",
    "# Match MobileInsight time\n",
    "ul_sent_df['timestamp'] = pd.to_datetime(ul_sent_df['timestamp']) + ul_time_diff\n",
    "dl_sent_df['timestamp'] = pd.to_datetime(dl_sent_df['timestamp']) + dl_time_diff\n",
    "\n",
    "# df that are declared lost but may not really lost\n",
    "ul_lost_df = pd.read_csv(ul_lost_file)\n",
    "dl_lost_df = pd.read_csv(dl_lost_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lost_data_from_df(df):\n",
    "    lost_data_df = df[df['lost']==True]\n",
    "    return lost_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df that the packet really lost\n",
    "ul_real_lost_df = get_lost_data_from_df(ul_lost_df)\n",
    "dl_real_lost_df = get_lost_data_from_df(dl_lost_df)\n",
    "\n",
    "print(len(ul_real_lost_df), len(dl_real_lost_df))\n",
    "print(len(ul_lost_df), len(dl_lost_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_lost_df['timestamp'] = pd.to_datetime(ul_lost_df['timestamp'])\n",
    "dl_lost_df['timestamp'] = pd.to_datetime(dl_lost_df['timestamp'])\n",
    "\n",
    "ul_lost_df['ho_type'] = 0\n",
    "dl_lost_df['ho_type'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_real_lost_df['timestamp'] = pd.to_datetime(ul_real_lost_df['timestamp'])\n",
    "dl_real_lost_df['timestamp'] = pd.to_datetime(dl_real_lost_df['timestamp'])\n",
    "\n",
    "ul_real_lost_df['ho_type'] = 0\n",
    "dl_real_lost_df['ho_type'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handover section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_records_within_1_second(loss_latency_df, D, event_dict):\n",
    "    # Convert timestamp columns to datetime objects\n",
    "    loss_latency_df['timestamp'] = pd.to_datetime(loss_latency_df['timestamp'])\n",
    "\n",
    "    # Initialize a dictionary to store the counts for each event type\n",
    "    event_counts = {}\n",
    "    # event = {'Event Type': [], 'HO Object': [], 'before': [], 'before_event': [], 'during':[], 'during_event': [], 'after': [], 'after_event': []}\n",
    "    events_list = []\n",
    "\n",
    "\n",
    "    # Loop through each event type in D\n",
    "    for event_type, ho_objects in D.items():\n",
    "        if event_type == \"Add_SCell\":\n",
    "            continue\n",
    "        event_counts[event_type] = {'before': [], 'during':[], 'after': []}\n",
    "\n",
    "        # Loop through each HO object in the current event type\n",
    "        for ho in ho_objects:\n",
    "            event = {'before': [], 'before_event': [], 'during':[], 'during_event': [], 'after': [], 'after_event': []}\n",
    "            if ho.end is not None:\n",
    "                start = ho.start\n",
    "                end = ho.end\n",
    "                sec_before_start = ho.start - timedelta(seconds=1)\n",
    "                sec_after_end = ho.end + timedelta(seconds=1)\n",
    "            else:\n",
    "                # continue\n",
    "                start = ho.start\n",
    "                end = ho.start\n",
    "                sec_before_start = ho.start - timedelta(seconds=1)\n",
    "                sec_after_end = ho.start + timedelta(seconds=1)\n",
    "            # print(start_time, ho.start, loss_latency_df['timestamp'])\n",
    "\n",
    "            # Filter and display the records in loss_latency_df within the specified time range\n",
    "            relevant_records_before = loss_latency_df[(start > loss_latency_df['timestamp']) & (loss_latency_df['timestamp'] >= sec_before_start)]\n",
    "            relevant_records_after = loss_latency_df[(end < loss_latency_df['timestamp']) & (loss_latency_df['timestamp'] <= sec_after_end)]\n",
    "            relevant_records_during = loss_latency_df[(start <= loss_latency_df['timestamp']) & (loss_latency_df['timestamp'] <= end)]\n",
    "\n",
    "            for records_df in [relevant_records_before, relevant_records_during, relevant_records_after]:\n",
    "                records_df.loc[records_df['ho_type'] == 0, 'ho_type'] = event_dict[event_type]\n",
    "\n",
    "            loss_latency_df.loc[relevant_records_before.index] = relevant_records_before\n",
    "            loss_latency_df.loc[relevant_records_during.index] = relevant_records_during\n",
    "            loss_latency_df.loc[relevant_records_after.index] = relevant_records_after\n",
    "            \n",
    "            # print(relevant_records_before['ho_type'])\n",
    "\n",
    "            event_counts[event_type]['before'].append(len(relevant_records_before))\n",
    "            # event_counts[event_type]['before_event'].append(relevant_records_before)\n",
    "            event_counts[event_type]['after'].append(len(relevant_records_after))\n",
    "            # event_counts[event_type]['after_event'].append(relevant_records_after)\n",
    "            event_counts[event_type]['during'].append(len(relevant_records_during))\n",
    "            # event_counts[event_type]['during_event'].append(relevant_records_during)\n",
    "\n",
    "            event['Event Type'] = f\"{event_type}\"\n",
    "            event['HO Object'] = f\"{ho}\"\n",
    "            event['before'] = len(relevant_records_before)\n",
    "            event['before_event'] = relevant_records_before\n",
    "            event['during'] = len(relevant_records_during)\n",
    "            event['during_event'] = relevant_records_during\n",
    "            event['after'] = len(relevant_records_after)\n",
    "            event['after_event'] = relevant_records_after\n",
    "\n",
    "            events_list.append(event)\n",
    "\n",
    "    return events_list, event_counts, loss_latency_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list_ul, event_counts_ul, ul_lost_df = count_records_within_1_second(ul_lost_df, HOs, event_dict)\n",
    "event_list_dl, event_counts_dl, dl_lost_df = count_records_within_1_second(dl_lost_df, HOs, event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list_ul_real, event_counts_ul_real, ul_real_lost_df = count_records_within_1_second(ul_real_lost_df, HOs, event_dict)\n",
    "event_list_dl_real, event_counts_dl_real, dl_real_lost_df = count_records_within_1_second(dl_real_lost_df, HOs, event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_event_sums_lists(event_counts):\n",
    "    success_sum_before = {}\n",
    "    success_sum_during = {}\n",
    "    success_sum_after = {}\n",
    "    failure_sum_before = {}\n",
    "    failure_sum_after = {}\n",
    "    # Initialize lists to store the sums of before, during, and after counts\n",
    "    success_sum_before_list = []\n",
    "    success_sum_during_list = []\n",
    "    success_sum_after_list = []\n",
    "    failure_sum_before_list = []\n",
    "    failure_sum_after_list = []\n",
    "\n",
    "    # Loop through each event type\n",
    "    for event_type, counts in event_counts.items():\n",
    "        # Initialize sums for this event type\n",
    "        if (event_type == 'RLF_II') or (event_type == 'RLF_III') or (event_type == 'SCG_RLF'):\n",
    "            failure_sum_before[event_type] = sum(counts['before'])\n",
    "            failure_sum_after[event_type] = sum(counts['after'])\n",
    "            failure_sum_before_list.append(sum(counts['before']))\n",
    "            failure_sum_after_list.append(sum(counts['after']))\n",
    "            \n",
    "        elif (event_type != 'Add_SCell'):\n",
    "            success_sum_before[event_type] = sum(counts['before'])\n",
    "            success_sum_during[event_type] = sum(counts['during'])\n",
    "            success_sum_after[event_type] = sum(counts['after'])\n",
    "            success_sum_before_list.append(sum(counts['before']))\n",
    "            success_sum_during_list.append(sum(counts['during']))\n",
    "            success_sum_after_list.append(sum(counts['after']))\n",
    "\n",
    "    return success_sum_before_list, success_sum_during_list, success_sum_after_list, failure_sum_before_list, failure_sum_after_list, success_sum_before, success_sum_during, success_sum_after, failure_sum_before, failure_sum_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_sums(time, port, success_sum_before_list, success_sum_during_list, success_sum_after_list,\n",
    "                    failure_sum_before_list, failure_sum_after_list):\n",
    "    x = ['Conn_Rel',\n",
    "         'Conn_Req',  # Setup\n",
    "         'LTE_HO',  # LTE -> newLTE\n",
    "         'MN_HO',  # LTE + NR -> newLTE + NR\n",
    "         'MN_HO_to_eNB',  # LTE + NR -> newLTE\n",
    "         'SN_setup',  # LTE -> LTE + NR => NR setup\n",
    "         'SN_Rel',  # LTE + NR -> LTE\n",
    "         'SN_HO',  # LTE + NR -> LTE + newNR\n",
    "         ]\n",
    "\n",
    "    w = 0.2\n",
    "\n",
    "    # Create an array of indices for x-axis positioning\n",
    "    indices = np.arange(len(x))\n",
    "\n",
    "    # Create a wider figure (e.g., width=10 inches, height=6 inches)\n",
    "    # plt.figure(figsize=(12, 5))\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 5))  # 2 rows, 1 column of subplots\n",
    "    ax1.bar(indices, success_sum_before_list, color='#edc56d', width=0.15, align='edge', label='before event')\n",
    "    ax1.bar(indices + 1.1 * w, success_sum_during_list, color='#6db6ed', width=0.15, label='during event')\n",
    "    ax1.bar(indices + 1.8 * w, success_sum_after_list, color='#e4a2f2', width=0.15, label='after event')\n",
    "\n",
    "    # Set custom x-axis labels\n",
    "    ax1.set_xticks(indices + w)\n",
    "    ax1.set_xticklabels(x)\n",
    "    ax1.legend()\n",
    "\n",
    "    x2 = ['RLF_II',  # fail but reestablishment success\n",
    "          'RLF_III',  # fail but reestablishment reject\n",
    "          'SCG_RLF'\n",
    "          ]\n",
    "\n",
    "    # Create an array of indices for x-axis positioning\n",
    "    indices2 = np.arange(len(x2))\n",
    "\n",
    "    ax2.bar(indices2, failure_sum_before_list, color='#edc56d', width=0.15, align='edge', label='before event')\n",
    "    ax2.bar(indices2 + 1.6 * w, failure_sum_after_list, color='#e4a2f2', width=0.15, label='after event')\n",
    "\n",
    "    # Set custom x-axis labels\n",
    "    ax2.set_xticks(indices2 + 1 * w)\n",
    "    ax2.set_xticklabels(x2)\n",
    "    ax2.legend()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figure_path}/ho_events_{time}_{port}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function and store the results\n",
    "success_sum_before_list_ul, success_sum_during_list_ul, success_sum_after_list_ul, failure_sum_before_list_ul, failure_sum_after_list_ul, success_sum_before_ul, success_sum_during_ul, success_sum_after_ul, failure_sum_before_ul, failure_sum_after_ul = calculate_event_sums_lists(event_counts_ul)\n",
    "\n",
    "# Print the results\n",
    "print(\"Success Sum Before List:\", success_sum_before_list_ul)\n",
    "print(\"Success Sum During List:\", success_sum_during_list_ul)\n",
    "print(\"Success Sum After List:\", success_sum_after_list_ul)\n",
    "print(\"Failure Sum Before List:\", failure_sum_before_list_ul)\n",
    "print(\"Failure Sum After List:\", failure_sum_after_list_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event_sums(time, ul_port, success_sum_before_list_ul, success_sum_during_list_ul, success_sum_after_list_ul, failure_sum_before_list_ul, failure_sum_after_list_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function and store the results\n",
    "success_sum_before_list_dl, success_sum_during_list_dl, success_sum_after_list_dl, failure_sum_before_list_dl, failure_sum_after_list_dl, success_sum_before_dl, success_sum_during_dl, success_sum_after_dl, failure_sum_before_dl, failure_sum_after_dl = calculate_event_sums_lists(event_counts_dl)\n",
    "\n",
    "# Print the results\n",
    "print(\"Success Sum Before List:\", success_sum_before_list_dl)\n",
    "print(\"Success Sum During List:\", success_sum_during_list_dl)\n",
    "print(\"Success Sum After List:\", success_sum_after_list_dl)\n",
    "print(\"Failure Sum Before List:\", failure_sum_before_list_dl)\n",
    "print(\"Failure Sum After List:\", failure_sum_after_list_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event_sums(time, dl_port, success_sum_before_list_dl, success_sum_during_list_dl, success_sum_after_list_dl, failure_sum_before_list_dl, failure_sum_after_list_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio that packet loss in stable or unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated by \"REAL\" lost\n",
    "success_ho_lost_sum_ul = len(ul_real_lost_df[(ul_real_lost_df['ho_type'] >= 1) & (ul_real_lost_df['ho_type'] <= 8)])\n",
    "failure_ho_lost_sum_ul = len(ul_real_lost_df[(ul_real_lost_df['ho_type'] >= 9) & (ul_real_lost_df['ho_type'] <= 11)])\n",
    "ho_lost_sum_ul = success_ho_lost_sum_ul + failure_ho_lost_sum_ul\n",
    "ho_lost_ratio_ul = -1 if len(ul_real_lost_df) == 0 else ho_lost_sum_ul / len(ul_real_lost_df)\n",
    "\n",
    "success_ho_lost_sum_dl = len(dl_real_lost_df[(dl_real_lost_df['ho_type'] >= 1) & (dl_real_lost_df['ho_type'] <= 8)])\n",
    "failure_ho_lost_sum_dl = len(dl_real_lost_df[(dl_real_lost_df['ho_type'] >= 9) & (dl_real_lost_df['ho_type'] <= 11)])\n",
    "ho_lost_sum_dl = success_ho_lost_sum_dl + failure_ho_lost_sum_dl\n",
    "ho_lost_ratio_dl = -1 if len(dl_real_lost_df) == 0 else ho_lost_sum_dl / len(dl_real_lost_df)\n",
    "\n",
    "print(ho_lost_ratio_ul, ho_lost_ratio_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossProportion(data, time, port, comment):\n",
    "\n",
    "    labels = [key for key, value in data.items() if value != 0]\n",
    "    sizes = [value for value in data.values() if value != 0]\n",
    "    colors = [colors_dict[key] for key in labels]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    plt.title('Loss Proportion')\n",
    "    plt.tight_layout(rect=[0, 0, 0.7, 1])\n",
    "    plt.legend(labels, title=\"Event Types\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.savefig(f\"{figure_path}/{comment}pkl_proportion_{time}_{port}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pkl_sum_ul = {}\n",
    "success_pkl_sum_ul = {}\n",
    "failure_pkl_sum_ul = {}\n",
    "\n",
    "for event_type, ho_type in event_dict.items():\n",
    "    # Calculate the sum for each event type\n",
    "    if ho_type in range(1, 9):\n",
    "        success_pkl_sum_ul[event_type] = len(ul_lost_df[ul_lost_df['ho_type'] == ho_type])\n",
    "    if ho_type in range(9, 12):\n",
    "        failure_pkl_sum_ul[event_type] = len(ul_lost_df[ul_lost_df['ho_type'] == ho_type])\n",
    "\n",
    "all_pkl_sum_ul = {**success_pkl_sum_ul, **failure_pkl_sum_ul}\n",
    "all_pkl_sum_ul['stable'] = len(ul_lost_df[ul_lost_df['ho_type'] == 0])\n",
    "\n",
    "print(success_pkl_sum_ul)\n",
    "print(failure_pkl_sum_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pkl_sum_dl = {}\n",
    "success_pkl_sum_dl = {}\n",
    "failure_pkl_sum_dl = {}\n",
    "\n",
    "for event_type, ho_type in event_dict.items():\n",
    "    # Calculate the sum for each event type\n",
    "    if ho_type in range(1, 9):\n",
    "        success_pkl_sum_dl[event_type] = len(dl_lost_df[dl_lost_df['ho_type'] == ho_type])\n",
    "    if ho_type in range(9, 12):\n",
    "        failure_pkl_sum_dl[event_type] = len(dl_lost_df[dl_lost_df['ho_type'] == ho_type])\n",
    "\n",
    "all_pkl_sum_dl = {**success_pkl_sum_dl, **failure_pkl_sum_dl}\n",
    "all_pkl_sum_dl['stable'] = len(dl_lost_df[dl_lost_df['ho_type'] == 0])\n",
    "\n",
    "print(success_pkl_sum_dl)\n",
    "print(failure_pkl_sum_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pkl_sum_ul = {}\n",
    "success_real_pkl_sum_ul = {}\n",
    "failure_real_pkl_sum_ul = {}\n",
    "\n",
    "for event_type, ho_type in event_dict.items():\n",
    "    # Calculate the sum for each event type\n",
    "    if ho_type in range(1, 9):\n",
    "        success_real_pkl_sum_ul[event_type] = len(ul_real_lost_df[ul_real_lost_df['ho_type'] == ho_type])\n",
    "    if ho_type in range(9, 12):\n",
    "        failure_real_pkl_sum_ul[event_type] = len(ul_real_lost_df[ul_real_lost_df['ho_type'] == ho_type])\n",
    "\n",
    "all_real_pkl_sum_ul = {**success_real_pkl_sum_ul, **failure_real_pkl_sum_ul}\n",
    "all_real_pkl_sum_ul['stable'] = len(ul_real_lost_df[ul_real_lost_df['ho_type'] == 0])\n",
    "\n",
    "print(len(ul_real_lost_df), success_ho_lost_sum_ul, failure_ho_lost_sum_ul)\n",
    "print(success_real_pkl_sum_ul)\n",
    "print(failure_real_pkl_sum_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pkl_sum_dl = {}\n",
    "success_real_pkl_sum_dl = {}\n",
    "failure_real_pkl_sum_dl = {}\n",
    "\n",
    "for event_type, ho_type in event_dict.items():\n",
    "    # Calculate the sum for each event type\n",
    "    if ho_type in range(1, 9):\n",
    "        success_real_pkl_sum_dl[event_type] = len(dl_real_lost_df[dl_real_lost_df['ho_type'] == ho_type])\n",
    "    if ho_type in range(9, 12):\n",
    "        failure_real_pkl_sum_dl[event_type] = len(dl_real_lost_df[dl_real_lost_df['ho_type'] == ho_type])\n",
    "\n",
    "all_real_pkl_sum_dl = {**success_real_pkl_sum_dl, **failure_real_pkl_sum_dl}\n",
    "all_real_pkl_sum_dl['stable'] = len(dl_real_lost_df[dl_real_lost_df['ho_type'] == 0])\n",
    "\n",
    "print(success_real_pkl_sum_dl)\n",
    "print(failure_real_pkl_sum_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LossProportion(all_pkl_sum_ul, time, ul_port, \"\")\n",
    "LossProportion(all_real_pkl_sum_ul, time, ul_port, \"adjusted_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LossProportion(all_pkl_sum_dl, time, dl_port, \"\")\n",
    "LossProportion(all_real_pkl_sum_dl, time, dl_port, \"adjusted_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congestion Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CwndWithPkl(df, lost_df, time, port):\n",
    "    # Create a plot with events marked on the x-axis\n",
    "    plt.figure(figsize=(50, 10))\n",
    "\n",
    "    # Set x-axis as timestamp\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        lost_time = row['timestamp']\n",
    "        plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "\n",
    "    # Plot the congestion window\n",
    "    # sm01_ul['timestamp'] = pd.to_datetime(sm01_ul['timestamp'])\n",
    "    plt.plot(df['timestamp'], df['congestion_window'], marker='o', markersize=0.5, color='green', label='Congestion Window')\n",
    "\n",
    "    plt.title(\"Congestion Window & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figure_path}/pkl_cwnd_{time}_{port}.png\")\n",
    "    plt.show()\n",
    "\n",
    "def RttWithLenWithPkl(df, lost_df, time, port):\n",
    "    # Set the figure size to make the plot wider\n",
    "    fig, ax1 = plt.subplots(figsize=(50, 10))\n",
    "    # Plot the 'congestion_window' column on the primary y-axis\n",
    "\n",
    "    color2 = 'tab:blue'\n",
    "    ax1.set_ylim(0, 300)\n",
    "    ax1.set_ylabel('Latest RTT', color=color2)\n",
    "    ax1.plot(df['timestamp'], df['latest_rtt'], marker='s', markersize=1, color=color2, label='latest_rtt')\n",
    "    ax1.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # Plot the 'length' on the secondary y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    color3 = 'tab:green'\n",
    "    ax2.plot(df['timestamp'], df['length'], marker='s', markersize=1, color=color3, label='length')\n",
    "    ax2.tick_params(axis='y', labelcolor=color3)\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        lost_time = row['timestamp']\n",
    "        plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "\n",
    "    # Set title\n",
    "    plt.title(\"RTT & Stream Length & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figure_path}/rtt_length_{time}_{port}.png\")\n",
    "    plt.show()\n",
    "\n",
    "def HoWithPkl(ordered_HOs, lost_df, time, port, comment):\n",
    "    # Convert the list to a DataFrame\n",
    "    # df_events = pd.DataFrame(ordered_HOs, columns=['Event', 'Start Time', 'End Time'])\n",
    "    df_events = pd.DataFrame(ordered_HOs, columns=['Start Time', 'End Time'])\n",
    "\n",
    "    # Extract timestamp information from HO and MR objects\n",
    "    df_events['Start Time'] = df_events['Start Time'].apply(lambda x: x.start if hasattr(x, 'start') else (x.time if hasattr(x, 'time') else None))\n",
    "    df_events['End Time'] = df_events['End Time'].apply(lambda x: x.end if hasattr(x, 'end') else (x.time if hasattr(x, 'time') else None))\n",
    "\n",
    "    df_events['Start Time'] = pd.to_datetime(df_events['Start Time'])\n",
    "    df_events['End Time'] = pd.to_datetime(df_events['End Time'].fillna(df_events['Start Time']))\n",
    "\n",
    "    # Create a plot with events marked on the x-axis\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.plot(df_events['Start Time'], [0] * len(df_events), 'o', label='Start Time', markersize=2)\n",
    "    plt.plot(df_events['End Time'], [1] * len(df_events), 'o', label='End Time', markersize=2)\n",
    "\n",
    "    # Set x-axis as timestamp\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "\n",
    "    # Add event labels\n",
    "    # for i, event in df_events.iterrows():\n",
    "    #     plt.text(event['Start Time'], 0, f'{event[\"Event\"]} (Start)', fontsize=8, ha='right')\n",
    "    #     plt.text(event['End Time'], 1, f'{event[\"Event\"]} (End)', fontsize=8, ha='right')\n",
    "\n",
    "    # Draw rectangles for each section\n",
    "    for _, event in df_events.iterrows():\n",
    "        start_time = event['Start Time']\n",
    "        end_time = event['End Time']\n",
    "\n",
    "        # Add a rectangle for 1 second before the event start\n",
    "        rect_before = Rectangle((start_time - pd.Timedelta(seconds=1), -0.5), pd.Timedelta(seconds=1), 5, alpha=0.5, color='lightblue')\n",
    "        plt.gca().add_patch(rect_before)\n",
    "\n",
    "        # Add a rectangle for the event duration\n",
    "        rect = Rectangle((start_time, -0.5), end_time - start_time, 5, alpha=1, color='blue')\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "        # Add a rectangle for 1 second after the event end\n",
    "        rect_after = Rectangle((end_time, -0.5), pd.Timedelta(seconds=1), 5, alpha=0.5, color='lightblue')\n",
    "        plt.gca().add_patch(rect_after)\n",
    "\n",
    "    # Adding vertical lines for lost packets\n",
    "    for _, row in lost_df.iterrows():\n",
    "        if row['trigger'] == \"time_threshold\":\n",
    "            lost_time = row['timestamp']\n",
    "            plt.axvline(x=lost_time, color='brown', linestyle='--', label='Lost Packet')\n",
    "        else:\n",
    "            lost_time = row['timestamp']\n",
    "            plt.axvline(x=lost_time, color='coral', linestyle='--', label='Lost Packet')\n",
    "        \n",
    "\n",
    "    plt.title(f\"Handover & Packet Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figure_path}/{comment}ho_timeline_{time}_{port}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CwndWithPkl(ul_sent_df, ul_lost_df, time, ul_port)\n",
    "CwndWithPkl(dl_sent_df, dl_lost_df, time, dl_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RttWithLenWithPkl(ul_sent_df, ul_lost_df, time, ul_port)\n",
    "RttWithLenWithPkl(dl_sent_df, dl_lost_df, time, dl_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_weird_length = ul_sent_df[ul_sent_df['length'] != 1000]\n",
    "dl_weird_length = dl_sent_df[dl_sent_df['length'] != 1000]\n",
    "print(\"pkl:\", len(ul_lost_df), len(dl_lost_df))\n",
    "print(\"weird length:\", len(ul_weird_length), len(dl_weird_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoWithPkl(filtered_time_ordered_HO, ul_lost_df, time, ul_port, \"\")\n",
    "HoWithPkl(filtered_time_ordered_HO, dl_lost_df, time, dl_port, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the timeline for \"REAL\" packet loss\n",
    "HoWithPkl(filtered_time_ordered_HO, ul_real_lost_df, time, ul_port, \"adjusted_\")\n",
    "HoWithPkl(filtered_time_ordered_HO, dl_real_lost_df, time, dl_port, \"adjusted_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotHoFreq(all_ho_count):\n",
    "    # Sort the data by values in descending order\n",
    "    sorted_data = dict(sorted(all_ho_count.items(), key=lambda item: item[1], reverse=True))\n",
    "    print(sorted_data)\n",
    "    # Extract keys and values\n",
    "    keys = list(sorted_data.keys())\n",
    "    values = list(sorted_data.values())\n",
    "\n",
    "    # Plot the data with colors\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(keys, values, color=[colors_dict[key] for key in keys])\n",
    "    plt.xlabel('Event Type')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Frequency of Event Occurrence')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figure_path}/ho_frequency.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calulate the occurrence of every event\n",
    "ho_count = {key: len(value) for key, value in HOs.items() if key != \"Add_SCell\"}\n",
    "# Print the lengths dictionary\n",
    "print(ho_count)\n",
    "\n",
    "PlotHoFreq(ho_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTO count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_files(directory, ul_port, dl_port):\n",
    "    ul_sender_file = None\n",
    "    dl_sender_file = None\n",
    "    ul_rcver_file = None\n",
    "    dl_rcver_file = None\n",
    "    \n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file starts with \"processed_sent\"\n",
    "        if filename.startswith(\"log\"):\n",
    "            # Split the file name by \"_\"\n",
    "            parts = filename.split(\"_\")\n",
    "            print(parts)\n",
    "            # Check if the last part of the file name is the UL port\n",
    "            if parts[3].split(\".\")[0] == ul_port:\n",
    "                if \"client.csv\" in parts[4]:\n",
    "                    ul_sender_file = os.path.join(directory, filename)\n",
    "                elif \"server.csv\" in parts[4]:\n",
    "                    ul_rcver_file = os.path.join(directory, filename)\n",
    "            # Check if the last part of the file name is the DL port\n",
    "            elif parts[3].split(\".\")[0] == dl_port:\n",
    "                if \"server.csv\" in parts[4]:\n",
    "                    dl_sender_file = os.path.join(directory, filename)\n",
    "                elif \"client.csv\" in parts[4]:\n",
    "                    dl_rcver_file = os.path.join(directory, filename)\n",
    "\n",
    "    return {\"ul_sender_file\": ul_sender_file, \"dl_sender_file\": dl_sender_file, \"ul_rcver_file\": ul_rcver_file, \"dl_rcver_file\": dl_rcver_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files_dict = get_raw_files(f\"{database}/{date}/{exp_name}/{device}/{round}/raw\", ul_port, dl_port)\n",
    "print(raw_files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_sender_file = pd.read_csv(raw_files_dict[\"ul_sender_file\"], sep=',')\n",
    "dl_sender_file = pd.read_csv(raw_files_dict[\"dl_sender_file\"], sep=',')\n",
    "ul_rcver_file = pd.read_csv(raw_files_dict[\"ul_rcver_file\"], sep=',')\n",
    "dl_rcver_file = pd.read_csv(raw_files_dict[\"dl_rcver_file\"], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_sender_pto_df = ul_sender_file[(ul_sender_file['name'] == 'recovery:metrics_updated') & (ul_sender_file['data'].str.contains('pto_count'))]\n",
    "ul_sender_pto_df.reset_index(drop=True)\n",
    "# print(ul_sender_pto_df)\n",
    "\n",
    "dl_sender_pto_df = dl_sender_file[(dl_sender_file['name'] == 'recovery:metrics_updated') & (dl_sender_file['data'].str.contains('pto_count'))]\n",
    "dl_sender_pto_df.reset_index(drop=True)\n",
    "# print(dl_sender_pto_df)\n",
    "\n",
    "ul_rcver_pto_df = ul_rcver_file[(ul_rcver_file['name'] == 'recovery:metrics_updated') & (ul_rcver_file['data'].str.contains('pto_count'))]\n",
    "ul_rcver_pto_df.reset_index(drop=True)\n",
    "# print(ul_rcver_pto_df)\n",
    "\n",
    "dl_rcver_pto_df = dl_rcver_file[(dl_rcver_file['name'] == 'recovery:metrics_updated') & (dl_rcver_file['data'].str.contains('pto_count'))]\n",
    "dl_rcver_pto_df.reset_index(drop=True)\n",
    "print(dl_rcver_pto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPtoCnt(df):\n",
    "    # Extract the number after 'pto_count' using regular expressions\n",
    "    df['pto_count_value'] = df['data'].str.extract(r'pto_count\\': (\\d+)').astype(int)\n",
    "    # Convert 'time' column to numeric\n",
    "    df['time'] = pd.to_numeric(df['time'])\n",
    "    # Plot 'pto_count_value' against 'time'\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.plot(df['time'], df['pto_count_value'], marker='o', linestyle='')\n",
    "    plt.ylim(0)\n",
    "    plt.yticks(range(int(df['pto_count_value'].min()), int(df['pto_count_value'].max()) + 1))\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('pto_count_value')\n",
    "    plt.title('pto_count_value over Time')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPtoCnt(ul_sender_pto_df)\n",
    "PlotPtoCnt(dl_sender_pto_df)\n",
    "\n",
    "PlotPtoCnt(ul_rcver_pto_df)\n",
    "PlotPtoCnt(dl_rcver_pto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
